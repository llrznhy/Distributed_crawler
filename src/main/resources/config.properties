# Crawler Configuration
crawler.max.pages=1000
crawler.delay.ms=1000

node.id=node-1
crawler.max.depth=5
crawler.queue.size=1000
crawler.user.agent=Mozilla/5.0 (compatible; MyCrawler/1.0; +http://example.com/bot)
crawler.connect.timeout=5000
crawler.read.timeout=10000
session.timeout.ms=45000  # ??? 45 ?

# Storage Configuration
storage.path=./crawler_data
#baseDir=crawler_data
storage.format=json

# Kafka
kafka.bootstrap.servers=localhost:9092
kafka.group.id=crawler-group

zookeeper.connect=localhost:2181

crawler.batch.size=100
crawler.distribution.interval=5000

# retry configuration
url.retry.max=3
url.retry.interval=60000




log.dirs=D:/kafka/kafka_2.13-3.4.0/kafka-logs

# parser configuration
parser.thread.pool.size=5
parser.batch.size=100

# Download Configuration
downloader.timeout.connect=5000
downloader.timeout.read=5000
downloader.max.retries=3

# Parser Configuration
parser.extract.title=true
parser.extract.content=true
parser.extract.links=true
parser.extract.images=false

# Proxy Configuration
proxy.enabled=false
proxy.host=
proxy.port=